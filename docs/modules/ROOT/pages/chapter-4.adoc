
[[ch-4]]
= Fundamental Principles of Machine Learning


== Learning Objectives

By the end of this chapter, you will be able to:

[arabic]
. Define machine learning and explain how it differs from broader artificial intelligence
. Describe the end-to-end machine learning workflow: data preparation, training, evaluation and iteration, and inferencing
. Distinguish between supervised learning and unsupervised learning
. Explain regression analysis, identify when to use it, and interpret common regression evaluation metrics
. Compare binary classification and multiclass classification, including their algorithms and evaluation metrics
. Describe clustering as an unsupervised learning technique and interpret clustering evaluation metrics
. Outline the structure and training process of a deep neural network
. Select the appropriate machine learning technique for a given business scenario


[[sec-4-1]]
== What Is Machine Learning?

Machine learning (ML) is a subset of artificial intelligence in which computer systems improve their performance on a task by learning from data rather than following explicitly coded instructions. Instead of a programmer writing rules for every possible situation, an ML system examines large volumes of historical data, identifies patterns within that data, and uses those patterns to make predictions or decisions about new, previously unseen data.

Consider an online retailer that wants to recommend products to its customers. Rather than manually creating recommendation rules for every product combination, the retailer can feed purchase history into an ML system. The system detects patterns — customers who buy running shoes also tend to buy moisture-wicking socks — and uses those patterns to generate personalized recommendations automatically.

=== Why ML Matters for Organizations

ML enables organizations to automate analysis that would be impractical for humans to perform at scale. Common applications include:

* *Fraud detection* — Flagging suspicious financial transactions in real time
* *Predictive maintenance* — Anticipating equipment failures before they happen
* *Customer segmentation* — Grouping customers by behavior to tailor marketing
* *Demand forecasting* — Estimating future product demand to optimize inventory

=== ML vs. AI: Clarifying the Relationship

The terms "`artificial intelligence`" and "`machine learning`" are frequently used as though they mean the same thing, but they represent different levels of specificity. AI is the broad discipline concerned with building systems that can perform tasks normally requiring human intelligence — everything from voice assistants to autonomous vehicles. ML is one approach within AI that focuses specifically on enabling systems to learn from data. In other words, all ML is AI, but not all AI is ML.

[.definition]
.Definition: Machine Learning
****
A branch of artificial intelligence in which systems learn patterns from data to make predictions or decisions, without being explicitly programmed for each scenario.
****


[NOTE]
====
Think of a repetitive decision-making task in your daily life or work. Could that task benefit from a system that learns patterns from historical data? What data would the system need?
====



[[sec-4-2]]
== The Machine Learning Workflow

.Figure 4.1: The Machine Learning Workflow Pipeline
image::ch4/visual_4_1_ml_workflow.png[Four-stage pipeline: Prepare Data; Train Model; Evaluate and Iterate; Inferencing,width=85%]


Every ML project follows a general workflow. Understanding this workflow is essential both for the AI-900 exam and for communicating effectively about ML in professional settings.

=== Step 1 — Prepare the Data

.Figure 4.10: Features vs. Labels in a Dataset
image::ch4/visual_4_10_features_labels.png[Annotated data table with feature columns highlighted in blue and label column highlighted in green,width=85%]


ML models learn from data, so the quality of that data directly affects the quality of the model's predictions. The data used to train a model is called the *training dataset*. A typical dataset is organized like a spreadsheet: each row represents one observation (also called a record or example), and each column represents a characteristic of that observation.

Two critical concepts appear in every training dataset:

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Concept |Role |Example (Predicting House Prices)
|*Features* |The input variables the model uses to make its prediction |Square footage, number of bedrooms, neighborhood
|*Label* |The output value the model is trying to predict |Sale price
|===

Features are commonly represented by the variable *x* (often a vector of multiple values), and the label is represented by *y*.

[.definition]
.Definition: Feature
****
An individual measurable property or characteristic of a data point that serves as an input to a machine learning model.
****


[.definition]
.Definition: Label
****
The outcome or target value that a supervised learning model is trained to predict.
****


=== Common Data Quality Issues

Real-world data is rarely clean. Before training a model, practitioners must address problems that could distort results:

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Issue |Description |Common Solutions
|*Missing values* |Some records lack data in one or more columns |Replace with the column's mean or median (imputation); use a model to predict the missing value (predictive imputation)
|*Outliers* |Extreme values that differ significantly from the rest of the data |Remove if caused by error; apply mathematical transformations to reduce their influence; investigate whether they contain genuine insight
|*Duplicate records* |The same observation appears more than once |Use deduplication algorithms; enforce unique identifiers at the point of data entry
|*Inconsistent formats* |The same type of data is recorded differently (e.g., dates as "`10/05/2024`" vs. "`2024-10-05`") |Standardize formats through normalization rules; build preprocessing pipelines (ETL processes) to clean data before analysis
|===

The overall process of cleaning and organizing raw data is called *data preparation* (sometimes called data preprocessing or data wrangling).

[TIP]
====
The AI-900 exam does not require you to perform data cleaning yourself, but you should be able to recognize common data quality issues and understand why preparation matters.
====


=== Step 2 — Train the Model

Training is the process in which an algorithm analyzes the training dataset to discover the relationship between the features (x) and the label (y). The goal is to find a mathematical function that can take a set of feature values as input and produce a predicted label as output:

*y = f(x)*

The specific function depends on the type of algorithm used. A linear regression algorithm, for example, fits a straight line through the data. A logistic regression algorithm fits an S-shaped curve. The algorithm's job is to determine the parameters of that function so that predictions are as close to the actual labels as possible.

<<sec-4-7,Section 4.7>> examines how deep neural networks implement a more complex version of this training process.

=== Step 3 — Evaluate and Iterate

Once trained, the model's predictions are compared against actual outcomes using data the model has not seen before (called the *test dataset*). Evaluation metrics — which vary depending on the type of ML task — quantify how well the model performs.

If performance is not satisfactory, practitioners iterate: they may adjust the algorithm's settings (called *hyperparameters*), select different features, gather more data, or try a different algorithm entirely. This cycle of train-evaluate-adjust is repeated until the model meets acceptable performance standards.

=== Step 4 — Use Inferencing

Once a model is trained and validated, it can be deployed to make predictions on new data. This process is called *inferencing*. The model receives new feature values and outputs a predicted label, often written as *y-hat* (symbolized as y with a circumflex: ŷ) to indicate that the value is an estimate, not a guaranteed outcome.

[.definition]
.Definition: Inferencing
****
The process of using a trained machine learning model to generate predictions on new, previously unseen data.
****


[.definition]
.Definition: Hyperparameter
****
A configuration setting external to the model itself (such as learning rate or number of iterations) that is adjusted by the practitioner to improve model performance.
****



[[sec-4-3]]
== Types of Machine Learning

.Figure 4.8: Supervised vs. Unsupervised Learning
image::ch4/visual_4_8_supervised_unsupervised.png[Two-panel comparison showing supervised learning with labels and unsupervised learning discovering clusters,width=85%]


At the highest level, ML techniques are divided into two broad categories based on whether the training data includes labels.

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Category |Labels Present? |Goal |Examples
|*Supervised learning* |Yes — each training example includes both features and a known label |Learn the mapping from features to labels so the model can predict labels for new data |Regression, classification
|*Unsupervised learning* |No — the training data contains only features, with no predefined labels |Discover hidden structure, patterns, or groupings within the data |Clustering
|===

Understanding this distinction is fundamental. The next sections examine the major techniques within each category.

[.reflection]
.Reflection
****
Imagine you have a dataset of customer transactions. If each transaction is labeled as "`fraudulent`" or "`legitimate,`" which category of ML would you use? What if no labels existed and you simply wanted to find unusual patterns?
****



[[sec-4-4]]
== Regression Analysis

Regression analysis is a supervised learning technique used when the label you want to predict is a *continuous numerical value* — a number that can fall anywhere along a range. Examples include predicting temperature, estimating revenue, or forecasting the price of a product.

=== How Regression Works

The general process follows the ML workflow described in <<sec-4-2,Section 4.2>>, with some specifics:

[arabic]
. *Split the data* — Divide the dataset into subsets. A common split reserves a portion for training, a portion for validation (to fine-tune model settings), and a portion for testing (to evaluate final performance).

[.definition]
.Definition: Train the model
****
A subset of data used during model development to tune hyperparameters and assess model generalization before final evaluation on the test set. It is distinct from both the training set (used to train the model) and the test set (used for final evaluation). 2. *Train the model* — Apply a regression algorithm to the training data. The algorithm identifies the mathematical relationship between the features and the numerical label. 3. *Validate and fine-tune* — Use the validation set to adjust hyperparameters and improve the model's ability to generalize beyond the training data. 4. *Test the model* — Generate predictions on the test set and compare predicted values (ŷ) to actual values (y). 5. *Evaluate and iterate* — Use evaluation metrics to measure accuracy. If performance is insufficient, revisit earlier steps.
****


=== Linear Regression: A Core Algorithm

Linear regression is one of the simplest and most widely used regression algorithms. It fits a straight line (called the *line of best fit*) through the data points in a way that minimizes the overall distance between the line and the actual data points.

For a single feature, the relationship can be visualized as a scatter plot with a trend line. The slope of the line indicates how much the predicted label changes for each unit increase in the feature. For example, if you are predicting concert ticket prices based on an artist's popularity rating, a steeper slope means that small increases in popularity lead to larger increases in ticket price.

When a model includes multiple features — as in the house price example where square footage, number of bedrooms, and neighborhood are all inputs — the algorithm fits a multi-dimensional surface rather than a single line, though the underlying principle of minimizing prediction error remains the same.

[.definition]
.Definition: Linear Regression
****
A regression algorithm that models the relationship between features and a numerical label by fitting a straight line through the data.
****


=== Data Splitting Strategies

.Figure 4.11: Data Splitting Strategies
image::ch4/visual_4_11_data_splitting.png[Partitioned bar showing training; validation; and test splits with K-fold cross-validation diagram below,width=85%]


How you divide your data matters. Different strategies are appropriate for different situations:

The strategies below range from simple one-time splits to more sophisticated iterative approaches. If you are new to data splitting, start with random and stratified splitting before working up to k-fold cross-validation.

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Strategy |Description |Best Used When
|*Random splitting* |Data is divided randomly into training, validation, and test sets |Data points are independent and identically distributed
|*Stratified splitting* |The split preserves the proportional representation of key feature ranges or categories |Certain value ranges are underrepresented and you need balanced subsets
|*Time-based splitting* |Older data is used for training; newer data is used for testing |The data has a chronological order (time-series data)
|*K-fold cross-validation* |Data is divided into _k_ equal subsets; the model is trained _k_ times, each time using a different subset as the test set |You want a more robust estimate of model performance, especially with limited data
|===

=== Evaluation Metrics for Regression

.Figure 4.9: Regression Evaluation Metrics
image::ch4/visual_4_9_regression_metrics.png[Scatter plot with regression line showing residuals and annotations for MAE; MSE; RMSE; and R-squared,width=75%]


After generating predictions, you need to measure how far those predictions are from the actual values. Four metrics are commonly used:

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Metric |What It Measures |How to Interpret
|*Mean Absolute Error (MAE)* |The average of the absolute differences between predicted and actual values |Expressed in the same units as the label; lower is better. If MAE = 5 for a price prediction model, the model is off by $5 on average.
|*Mean Squared Error (MSE)* |The average of the squared differences between predicted and actual values |Squaring amplifies larger errors, making MSE more sensitive to outliers. Units are squared (e.g., dollars squared), so the number is less intuitive on its own.
|*Root Mean Squared Error (RMSE)* |The square root of MSE |Returns the error to the original units of the label while still penalizing larger errors more heavily than MAE.
|*Coefficient of Determination (R-squared / R²)* |The proportion of variance in the actual values that the model explains |Ranges from 0 to 1. An R² of 0.85 means the model explains 85% of the variation in the data. Values closer to 1 indicate a better fit.
|===

[TIP]
====
You do not need to memorize the mathematical formulas for these metrics on the AI-900 exam. Focus on understanding what each metric tells you about model performance and when you would use it.
====


[.reflection]
.Reflection
****
A model predicting delivery times has an RMSE of 12 minutes. A second model predicting the same thing has an R² of 0.91. Which metric tells you more about whether the model is useful in practice? Why might you want to know both?
****


=== The Iterative Nature of Model Development

Achieving a good model is rarely a one-step process. Data scientists typically repeat the training cycle multiple times, adjusting three main levers:

* *Feature selection and engineering* — Choosing which features to include and creating new features from existing data
* *Algorithm selection* — Trying different algorithms to see which best captures the patterns in the data
* *Hyperparameter tuning* — Adjusting the algorithm's configuration settings to optimize performance


[[sec-4-5]]
== Classification

Classification is a supervised learning technique used when the label is a *discrete category* rather than a continuous number. The model's job is to assign each new data point to one of a set of predefined categories (also called classes).

=== Binary Classification

.Figure 4.4: The Sigmoid Function Curve
image::ch4/visual_4_4_sigmoid_function.png[S-shaped sigmoid curve showing probability threshold at 0.5 for binary classification,width=70%]


Binary classification is the simplest form: the model predicts one of exactly *two* possible outcomes. Common examples include:

* Email: spam or not spam
* Medical test: positive or negative
* Loan application: default or no default

==== How Binary Classification Works

The model analyzes feature values and calculates the *probability* that a given observation belongs to the positive class (often labeled 1). If the probability exceeds a decision boundary (called a *threshold*, typically set at 0.5), the model predicts the positive class. Otherwise, it predicts the negative class (labeled 0).

==== Logistic Regression

Despite its name, *logistic regression* is a classification algorithm, not a regression algorithm. It is one of the most commonly used algorithms for binary classification. Logistic regression produces an S-shaped curve called a *sigmoid function* that maps any input value to a probability between 0 and 1.

For example, a bank building a loan default prediction model might use logistic regression. The sigmoid curve would show how the probability of default changes as the applicant's credit score changes. Applicants whose predicted probability exceeds the 0.5 threshold would be classified as likely to default.

[.definition]
.Definition: Logistic Regression
****
A classification algorithm that uses a sigmoid function to model the probability of an observation belonging to one of two classes. Despite the word "`regression`" in its name, it is used for classification tasks.
****


[.definition]
.Definition: Sigmoid Function
****
An S-shaped mathematical curve that maps input values to output values between 0 and 1, commonly used to represent probabilities in binary classification.
****


=== The Confusion Matrix

.Figure 4.2: The Confusion Matrix
image::ch4/visual_4_2_confusion_matrix.png[Color-coded 2x2 matrix showing True Positive; False Negative; False Positive; and True Negative quadrants,width=70%]


To evaluate a binary classification model, you first organize its predictions into a *confusion matrix* — a table that compares the model's predicted labels against the actual labels.

[cols=",,",options="header",]
|===
| |*Predicted Positive* |*Predicted Negative*
|*Actually Positive* |True Positive (TP) |False Negative (FN)
|*Actually Negative* |False Positive (FP) |True Negative (TN)
|===

Each cell captures a specific type of outcome:

[width="100%",cols="50%,50%",options="header",]
|===
|Outcome |Meaning
|*True Positive (TP)* |The model correctly predicted the positive class
|*True Negative (TN)* |The model correctly predicted the negative class
|*False Positive (FP)* |The model incorrectly predicted positive when the actual class was negative (also called a Type I error)
|*False Negative (FN)* |The model incorrectly predicted negative when the actual class was positive (also called a Type II error)
|===

[.definition]
.Definition: Confusion Matrix
****
A table that summarizes the performance of a classification model by displaying the counts of true positives, true negatives, false positives, and false negatives.
****


To read this table: find the row for the actual class of the observation, then move to the column for what the model predicted. For example, if an observation was actually positive but the model predicted negative, that falls in the top-right cell: a False Negative. If the observation was actually negative and the model correctly predicted negative, that is the bottom-right cell: a True Negative.

[TIP]
====
The confusion matrix is very likely to appear on the AI-900 exam. Commit the four outcomes (TP, TN, FP, FN) to memory and practice identifying each one in a scenario.
====


=== Evaluation Metrics for Binary Classification

.Figure 4.5: ROC Curve with AUC
image::ch4/visual_4_5_roc_curve.png[Plot showing ROC curve with shaded AUC area comparing model performance to random guessing,width=70%]


.Figure 4.12: Classification Metrics Formula Cards
image::ch4/visual_4_12_classification_metrics.png[Reference cards for Accuracy; Precision; Recall; and F1 Score with formulas and interpretations,width=85%]


Several metrics are derived from the confusion matrix. Each highlights a different aspect of model performance:

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Metric |Formula |What It Tells You
|*Accuracy* |(TP {plus} TN) / (TP {plus} TN {plus} FP {plus} FN) |The proportion of all predictions that were correct. Simple but can be misleading when classes are imbalanced.
|*Precision* |TP / (TP {plus} FP) |Of all the observations the model predicted as positive, how many were actually positive? High precision means few false alarms.
|*Recall (Sensitivity)* |TP / (TP {plus} FN) |Of all the observations that were actually positive, how many did the model correctly identify? High recall means few missed cases.
|*F1 Score* |2 x (Precision x Recall) / (Precision {plus} Recall) |The harmonic mean of precision and recall, providing a single balanced measure. Especially useful when you need both precision and recall to be high.
|*AUC (Area Under the ROC Curve)* |Varies (graphical) |Measures the model's ability to distinguish between classes across all possible thresholds. Theoretically ranges from 0 to 1. Values below 0.5 indicate the model is performing worse than random chance (a sign that predictions may be inverted). For practical purposes, a well-functioning model will score between 0.5 and 1.0, where 0.5 represents random guessing and 1.0 represents perfect classification.
|===

[TIP]
====
Before reading further, try this: given a confusion matrix where TP = 80, FP = 20, FN = 10, and TN = 90, calculate precision using the formula Precision = TP / (TP {plus} FP). Then check your work: Precision = 80 / (80 {plus} 20) = 0.80, meaning 80% of the model's positive predictions were correct.
====


==== Understanding AUC and the ROC Curve

The *Receiver Operating Characteristic (ROC) curve* is a plot that shows how the True Positive Rate (recall) and the False Positive Rate change as the classification threshold is varied. The *Area Under the Curve (AUC)* summarizes this plot as a single number:

* *AUC = 1.0* — The model perfectly separates the two classes
* *AUC = 0.5* — The model is no better than random guessing
* *AUC between 0.5 and 1.0* — The higher the value, the better the model distinguishes between classes

[.reflection]
.Reflection
****
Imagine you are building a model to detect a rare but serious disease. Would you prioritize precision or recall? What are the consequences of false positives versus false negatives in this context?
****


=== Multiclass Classification

Multiclass classification extends the concept to scenarios where there are *three or more* possible classes. For example, classifying an image of a flower as a rose, a daisy, or a tulip is a multiclass problem.

==== Algorithmic Approaches

Two common approaches handle multiclass problems:

[width="100%",cols="50%,50%",options="header",]
|===
|Approach |How It Works
|*One-vs-Rest (OVR)* |Builds a separate binary classifier for each class. Each classifier answers the question: "`Does this observation belong to class X or not?`" The class whose classifier produces the highest probability wins.
|*Multinomial* |Trains a single model that outputs a probability distribution across all classes simultaneously. The probabilities sum to 1, and the class with the highest probability is the prediction.
|===

For example, a multinomial model evaluating a flower might output: ++[++0.15, 0.25, 0.60++]++. This means a 15% chance of rose, a 25% chance of daisy, and a 60% chance of tulip. The model predicts tulip.

==== Evaluating Multiclass Models

The confusion matrix for a multiclass classifier has one row and one column for each class. Metrics such as accuracy, precision, recall, and F1 score can be calculated individually for each class and then aggregated to produce an overall measure of model performance.

[.definition]
.Definition: Multiclass Classification
****
A classification task in which the model predicts one of three or more possible categories for each observation.
****



[[sec-4-6]]
== Clustering

Clustering is an *unsupervised learning* technique. Unlike regression and classification, clustering does not use labeled data. Instead, the algorithm examines the features of each data point and groups similar data points together into *clusters*. The clusters themselves serve as labels that the model discovers on its own.

=== When to Use Clustering

Clustering is valuable when you do not know in advance what groups exist in your data. Common applications include:

* *Customer segmentation* — Grouping customers by purchasing patterns to design targeted marketing campaigns
* *Anomaly detection* — Identifying data points that do not fit neatly into any cluster, which may indicate fraud or system errors
* *Document organization* — Grouping articles or support tickets by topic
* *Biological research* — Grouping genes or organisms by shared characteristics

=== K-Means Clustering

.Figure 4.6: K-Means Clustering Step-by-Step
image::ch4/visual_4_6_kmeans_clustering.png[Multi-panel sequence showing random centroids; point assignment; centroid movement; and final clusters,width=85%]


K-means is one of the most widely used clustering algorithms. The process works as follows:

[arabic]
. *Choose k* — Decide how many clusters you want to create. This number is specified in advance.
. *Initialize centroids* — Place _k_ points randomly in the feature space. These are the initial cluster centers (called *centroids*).
. *Assign data points* — Calculate the distance from each data point to every centroid. Assign each data point to the nearest centroid.
. *Recalculate centroids* — Move each centroid to the average position of all data points assigned to it.
. *Repeat* — Continue alternating between assigning data points and recalculating centroids until the assignments stabilize (i.e., no data points change clusters between iterations).

[.definition]
.Definition: Centroid
****
The center point of a cluster, calculated as the mean of all data points assigned to that cluster in k-means clustering.
****


[.definition]
.Definition: K-Means Clustering
****
An unsupervised learning algorithm that partitions data into a specified number (k) of clusters by iteratively assigning data points to the nearest centroid and recalculating centroid positions.
****


=== Evaluation Metrics for Clustering

Because there are no known labels to compare against, clustering evaluation focuses on how well-separated and internally cohesive the clusters are:

[width="100%",cols="50%,50%",options="header",]
|===
|Metric |What It Measures
|*Average distance to cluster center* |How close, on average, each data point in a cluster is to its centroid. Lower values indicate tighter clusters.
|*Average distance to other centers* |How far, on average, each data point is from the centroids of other clusters. Higher values indicate better separation between clusters.
|*Maximum distance to cluster center* |The distance of the farthest data point from its centroid. Helps identify clusters with straggling outliers.
|*Silhouette score* |A value between -1 and 1 that combines cohesion and separation. A score near 1 means clusters are dense and well-separated. A score near 0 means clusters overlap. A negative score suggests data points may be assigned to the wrong cluster.
|===

[TIP]
====
For the AI-900 exam, remember that clustering is unsupervised (no labels) and that the silhouette score is the most commonly referenced metric for measuring cluster quality.
====



[[sec-4-7]]
== Deep Learning

A hospital wants to automatically flag chest X-rays that show signs of pneumonia. The variation in X-ray images is too complex for a traditional ML model to capture through manually defined features. A deep neural network can learn to identify relevant visual patterns — fluid buildup, shadowing, texture changes — directly from the image data, making it the appropriate choice for this task.

Deep learning (DL) is a specialized form of machine learning that uses *artificial neural networks* with multiple layers to learn complex patterns in data. The "`deep`" in deep learning refers to the depth (number of layers) of these networks. Deep learning models, often called *deep neural networks (DNNs)*, power many of today's most advanced AI capabilities, including image recognition, natural language understanding, and speech synthesis.

=== How a Neural Network Works

.Figure 4.7: Neural Network Architecture
image::ch4/visual_4_7_neural_network.png[Three-layer neural network diagram showing input; hidden; and output layers with connection weights,width=85%]


A neural network is organized into layers:

[width="100%",cols="50%,50%",options="header",]
|===
|Layer |Role
|*Input layer* |Receives the raw feature data. Each node in this layer corresponds to one feature.
|*Hidden layer(s)* |One or more intermediate layers that transform the input data. Each node (neuron) applies a mathematical function to its inputs, multiplied by learned *weights*, and passes the result through an *activation function*.
|*Output layer* |Produces the final prediction. For classification, this might be a set of probabilities for each class. For regression, it might be a single numerical value.
|===

=== The Training Process

.Figure 4.14: Backpropagation Concept Diagram
image::ch4/visual_4_14_backpropagation.png[Neural network diagram showing forward pass in blue and backward pass in red with loss calculation,width=85%]


The training steps below follow the same general workflow described in <<sec-4-2,Section 4.2>>, but with additional mechanisms to handle the complexity of multi-layer networks.

Training a neural network involves the following high-level steps:

[arabic]
. *Forward pass* — Feature data is fed into the input layer and propagated through the hidden layers to produce an output.
. *Calculate loss* — A *loss function* measures how far the predicted output is from the true label.
. *Backpropagation* — The network calculates how much each weight contributed to the error and adjusts the weights to reduce the loss.
. *Repeat over epochs* — The entire dataset is passed through the network multiple times (each pass is called an *epoch*) until the loss is minimized to an acceptable level.

Training deep neural networks is computationally intensive and typically requires specialized hardware such as *GPUs (Graphics Processing Units)*, which can perform many calculations in parallel.

[.definition]
.Definition: Backpropagation
****
The training process in a neural network in which the model calculates the contribution of each weight to the prediction error and adjusts the weights to improve accuracy.
****


[NOTE]
====
One complete pass of the entire training dataset through the neural network during the training process.
====


=== ML vs. Deep Learning: Key Differences

.Figure 4.13: Deep Learning vs. Traditional ML Comparison
image::ch4/visual_4_13_deep_learning_vs_ml.png[Side-by-side comparison of traditional ML and deep learning across complexity; data needs; and use cases,width=85%]


The AI-900 exam may ask you to compare traditional ML techniques with deep learning. The following table highlights the most important distinctions:

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Factor |Traditional ML |Deep Learning
|*Model complexity* |Simpler models with fewer parameters |Complex models with many layers and millions of parameters
|*Data requirements* |Can perform well with smaller, structured datasets |Generally requires large volumes of data to achieve high accuracy
|*Training time* |Typically faster to train |Requires significantly more time due to model complexity
|*Hardware requirements* |Can run on standard CPUs |Often requires GPUs or specialized AI accelerators
|*Interpretability* |Easier to understand why the model made a specific prediction |Often called a "`black box`" because the internal decision process is difficult to interpret
|*Use cases* |Tabular data, straightforward prediction tasks |Image recognition, natural language processing, speech, complex pattern recognition
|===

[.reflection]
.Reflection
****
Why might an organization choose a simpler ML model over a deep learning model, even if the deep learning model could be slightly more accurate? Consider factors beyond raw performance.
****



[[sec-4-8]]
== Choosing the Right ML Technique

.Figure 4.3: ML Technique Decision Flowchart
image::ch4/visual_4_3_ml_decision_tree.png[Decision tree for selecting regression; classification; clustering; or deep learning,width=85%]


When facing a new problem, selecting the appropriate ML technique depends on the nature of your data and the question you are trying to answer. The following decision framework can help:

[width="100%",cols="34%,33%,33%",options="header",]
|===
|If your goal is to… |And your data has… |Consider using…
|Predict a continuous number (e.g., price, temperature, revenue) |Features and a numerical label |*Regression*
|Categorize into one of two groups (e.g., yes/no, spam/not spam) |Features and a binary label |*Binary classification*
|Categorize into one of several groups (e.g., type of product, species) |Features and a multi-category label |*Multiclass classification*
|Discover natural groupings in the data |Features but no labels |*Clustering*
|Handle complex patterns in images, text, or speech |Large volumes of data (often unstructured) |*Deep learning*
|===

[TIP]
====
On the AI-900 exam, scenario-based questions may describe a business problem and ask you to identify the appropriate ML technique. Practice mapping real-world problems to the correct technique using the decision framework above.
====



== Chapter Summary

* *Machine learning* is a subset of AI in which systems learn from data to make predictions, rather than following explicitly coded rules.
* The ML workflow has four main phases: *data preparation*, *model training*, *evaluation*, and *inferencing* (using the model to predict on new data).
* *Supervised learning* uses labeled data and includes *regression* (predicting numerical values) and *classification* (predicting categorical values).
* *Unsupervised learning* works with unlabeled data; *clustering* groups similar data points together without predefined categories.
* *Regression* models are evaluated using MAE, MSE, RMSE, and R-squared (coefficient of determination).
* *Binary classification* predicts one of two outcomes and is commonly implemented with *logistic regression*. The *confusion matrix* (TP, TN, FP, FN) is the foundation for metrics including accuracy, precision, recall, F1 score, and AUC.
* *Multiclass classification* extends classification to three or more categories and can use one-vs-rest or multinomial algorithmic approaches.
* *Clustering* (e.g., k-means) discovers groups in unlabeled data and is evaluated with metrics such as the *silhouette score*.
* *Deep learning* uses multi-layered neural networks to learn complex patterns. It requires large datasets and significant computational resources but excels at tasks such as image recognition and natural language processing.
* This domain accounts for *20–25%* of the AI-900 exam, making it the single most heavily weighted topic area.

xref:chapter-5.adoc#ch-5[Chapter 5] explores how these machine learning concepts are implemented on the Azure platform using Azure Machine Learning, including tools such as AutoML and Azure Machine Learning Designer.


== Key Terms

[width="100%",cols="50%,50%",options="header",]
|===
|Term |Definition
|*Machine Learning (ML)* |A branch of AI in which systems learn patterns from data to make predictions or decisions without explicit programming
|*Feature* |An input variable or measurable property used by a model to make predictions
|*Label* |The target output value that a supervised learning model is trained to predict
|*Training Dataset* |The subset of data used to teach the model the relationship between features and labels
|*Test Dataset* |A held-out subset of data used to evaluate the model's performance on unseen data
|*Inferencing* |The process of using a trained model to generate predictions on new data
|*Hyperparameter* |A configuration setting (e.g., learning rate, number of clusters) set by the practitioner, not learned by the model
|*Supervised Learning* |ML where the training data includes both features and known labels
|*Unsupervised Learning* |ML where the training data contains only features, with no predefined labels
|*Validation Dataset* |A subset of data used during model development to tune hyperparameters and assess model generalization before final evaluation on the test set, distinct from both the training set and the test set
|*Regression* |A supervised learning technique that predicts a continuous numerical value
|*Linear Regression* |A regression algorithm that models the relationship between features and a numerical label by fitting a straight line
|*Classification* |A supervised learning technique that predicts a discrete category or class
|*Binary Classification* |A classification task with exactly two possible outcome categories
|*Multiclass Classification* |A classification task with three or more possible outcome categories
|*Logistic Regression* |A classification algorithm that uses a sigmoid function to estimate class probabilities, despite having "`regression`" in its name
|*Sigmoid Function* |An S-shaped curve that maps input values to probabilities between 0 and 1
|*Confusion Matrix* |A table summarizing classification results by comparing predicted labels to actual labels (TP, TN, FP, FN)
|*True Positive (TP)* |A correct prediction of the positive class
|*True Negative (TN)* |A correct prediction of the negative class
|*False Positive (FP)* |An incorrect prediction of the positive class when the actual class was negative (Type I error)
|*False Negative (FN)* |An incorrect prediction of the negative class when the actual class was positive (Type II error)
|*Activation Function* |A mathematical function applied to the output of a neuron in a neural network that introduces non-linearity, enabling the network to learn complex patterns
|*Accuracy* |The proportion of all predictions that were correct
|*Precision* |The proportion of positive predictions that were actually positive
|*Recall* |The proportion of actual positives that the model correctly identified
|*F1 Score* |The harmonic mean of precision and recall, balancing both metrics in a single value
|*AUC (Area Under the ROC Curve)* |A metric measuring a classifier's ability to distinguish classes across all thresholds (0.5 = random, 1.0 = perfect)
|*MAE (Mean Absolute Error)* |The average of absolute differences between predicted and actual values
|*MSE (Mean Squared Error)* |The average of squared differences between predicted and actual values, emphasizing larger errors
|*RMSE (Root Mean Squared Error)* |The square root of MSE, returning the error to original measurement units
|*R² (Coefficient of Determination)* |The proportion of variance in the data explained by the model (0 to 1; closer to 1 is better)
|*Clustering* |An unsupervised learning technique that groups data points by similarity without predefined labels
|*K-Fold Cross-Validation* |A data splitting strategy that divides data into k equal subsets, training the model k times and using a different subset as the test set each time, providing a more robust estimate of model performance than a single train/test split
|*K-Means Clustering* |A clustering algorithm that partitions data into k groups by iteratively assigning points to the nearest centroid
|*Centroid* |The center point of a cluster, calculated as the mean position of all assigned data points
|*Silhouette Score* |A clustering evaluation metric ranging from -1 to 1, indicating how well-separated and internally cohesive the clusters are
|*Deep Learning (DL)* |A subset of ML that uses artificial neural networks with multiple layers to model complex patterns
|*Neural Network* |A computational model inspired by biological neurons, composed of interconnected nodes organized in layers
|*Backpropagation* |The process by which a neural network adjusts its weights based on prediction errors to improve accuracy
|*Epoch* |One complete pass of the entire training dataset through a neural network
|*Loss Function* |A mathematical function that quantifies the difference between a model's predicted output and the true label
|*Weights* |The internal parameters of a neural network that are adjusted during training to improve predictions
|===


== Review Questions

Test your understanding of the material covered in this chapter.

[arabic]
. *A company wants to predict how many units of a product it will sell next quarter based on advertising budget, seasonality, and economic indicators. Which ML technique is most appropriate, and why?*
. *Explain the difference between a feature and a label. Provide an example of each using a scenario not discussed in this chapter.*
. *A binary classification model produces the following confusion matrix. Calculate the model's accuracy and recall.*
+
[cols=",,",options="header",]
|===
| |Predicted Positive |Predicted Negative
|Actually Positive |40 |10
|Actually Negative |5 |45
|===
. *Why can accuracy be a misleading metric when evaluating a classification model on an imbalanced dataset? What alternative metrics would you examine instead?*
. *Describe the k-means clustering algorithm in your own words. What must a practitioner decide before running the algorithm, and why is that decision significant?*
. *Compare supervised learning and unsupervised learning. For each, name one technique discussed in this chapter and describe a business scenario where it would be used.*
. *A colleague says, "`Logistic regression is a regression algorithm because it has '`regression`' in the name.`" How would you correct this misunderstanding?*
. *Describe the three types of layers in a deep neural network (input, hidden, output) and explain what happens during the training process. What is backpropagation and why is it necessary?*
. *A model predicting apartment rental prices produces the following evaluation results: MAE = $180, RMSE = $245, and R² = 0.72. Interpret each metric in plain language. Based on these results, would you consider the model ready for deployment? What might you do to improve it?*
. *A data scientist is building a model using sales transaction data from the past three years. Which data splitting strategy — random, stratified, time-based, or k-fold cross-validation — is most appropriate for this dataset, and why?*


== Additional Resources

* https://learn.microsoft.com/en-us/training/modules/fundamentals-machine-learning/[Microsoft Learn: Fundamental Principles of Machine Learning] (Free)
* https://learn.microsoft.com/en-us/training/paths/get-started-with-artificial-intelligence-on-azure/[Microsoft Learn: Azure AI Fundamentals – Machine Learning] (Free learning path)
* https://developers.google.com/machine-learning/crash-course[Google Machine Learning Crash Course] (Free)
* https://cs229.stanford.edu/[Stanford CS229 Machine Learning Course Notes] (Free lecture notes and materials)
* https://www.elementsofai.com/[Elements of AI: Chapter on Machine Learning] (Free, University of Helsinki)
* https://scikit-learn.org/stable/tutorial/machine_learning_map/[Scikit-learn Documentation: Choosing the Right Estimator] (Free reference for algorithm selection)
